## Project 3: "All aboard the struggle bus"<br/>
![computer on fire](https://aeraposo.github.io/Data-310-Public-Raposo/mac_fire.jpg)
**This isn't my computer but is certainly sounded like this might happen when I was running my CNN!**
**About the data:**<br/>
For project 3, we were provided with 10,000 images of Korle Gonno, a town in Accra, Ghana. Each image is 480x400 pixels and contains 3 bytes per pixel. Accra is ~225.7 km^2 so each of the 10,000 images represents 0.02257 km^2 of the area. The images, known as orthophotos, were taken from an aircraft and are of a high resolution (~60cm). For each photo, the approximate population residing within the pictured area was recorded in a csv file, where each entry corresponds to the assigned name of each photo (for example, the population of '1.jpeg' is the first record in the csv file).<br/>
**The process:**<br/>
Using the above dataset, I then built a model that predicts the population that resides in the area pictured in an image. I went about this process in 3 ways with varrying levels of success and run times (hence, "all aboard the struggle bus" became my personal slogan for the weekend). Before I began, I downloaded the labels (population sizes) csv and unpacked the zipfiles containing the images. After moving them into a file with my desired file path, I began my first attempt.<br/>
- Method 1: In my first attempt, after downloading the necessary libraries, I specified my data directory by using pathlib.Path(my_file_path). After verifying this step had worked by calling .glob on my directory and counting the accessed files, I used os.makedirs, pathlib, and a few other methods to make training and testing directories. I shuffled the images first and added 90% (9,000 images) to training and 10% (1,000 images) to testing. This was a super helpful step in my later attempts becuase it physically moved the images into their own folders with the paths I specified. I then wrote a for loop (seperate ones for training and testing) that paired the integer from each file name with its file path in a list. It appended each of these pairs to a list (making a tuple). I then sorted the list in ascending order by file integer and, in a second for loop, replaced the file integer with its population size specified in the csv. At this point I had 2 tuples (one for training and one for testing), each containing [(population size, image path), ... ] for each image. This is where things got tricky. I tried to replace the file path in the tuples with an array representing the associated image, with little success. Ultimately, I abandoned this method when Professor Frazier sent some helpful code in slack (thank you!).<br/>
- Method 2: In my second attempt, I made a DNN. After several hours of using the wrong loss funtion, my model ran! This excitement, however, was short lived as my loss was in the several million range. After messing around with the neurons per layer, my results improved and my loss dropped to ~400,000. After consulting my notes from week 2 when we compared the results of the DNN vs CNN on the mnist dataset, I decided that a CNN may have more success. I gave myself a quick pep talk and embarked on the final part of this trilogy.<br/>
- Method 3: Before building my CNN, I consulted the cats and dogs CNN we made last week. I coppied this CNN and changed out the functions, activations, and number neurons for each layer. In my last dense layer, I selected "linear" as my activation since the model predicts continuous values, however, I removed it after finding no significant differences in scores on smaller test batches. I recall that more convolutional and pooling layers can sometimes yield better results, however, I decided to proceed with just one convolutional and one pooling layer as my last run took 8 hours to fit. I fit my model on different sized subsets of the dataset and adjusted my model accordingly. On several occasions, I made mistakes in the input arguments for model.fit and ran out of data after up to an hour in to the compiling process. After scrupulously rechecking the formula for batch size, epochs, and steps per epoch, I began running the program with increasingly large subsets of the data. With each increase in data subset size, run time increased. I capped these increases after reaching a training subset size of 1,000 images and testing of 100 images becuase it took 8 hours to fit and my computer kept freezing and making distressed noises.
  - **More about my CNN:** Initially, my CNN had one convolutional and one pooling layer, followed by a flatten layer and two dense layers. For activation I used 'relu', which I chose over sigmoid since we are predicting a continuous value.
**Results:**
Something I quickly realized was that 'Accuracy' was not a helpful metric in evaluating the success of my model. This was because this number was often so low that it read '0000000 e0', so I decided to focus on MSE and MAE. MSE is an ancronym for mean squared error, a measure of the average squared distance of outputs/predictions from the true value. MAE stands for mean absolute error is the average ditance between each prediction and the actual value ([source](http://zerospectrum.com/2019/06/02/mae-vs-mse-vs-rmse/)). Both of these measures are used to gauge a model's performance- higher values generally indicate a poor model. Note that distance is >= 0. Next, I will detail four of my more notable CNN outputs.
  - **Run 1:** Before this run, I tried using smaller batches, fewer epochs, and smaller batch sizes. When the MAE and MSE remained high, I opted to increase my parameters. In this run, I used a training batch of 500 images and a testing batch of 50 images. I fit my model using epochs=10, steps_per_epoch = 10, and batch_size = 5. After just a few minutes, I was able to call model.evalute and got loss (MSE): 62.9714,  MAE: 7.9354. Not bad considering I started at over a million for loss! Determined to do better, I made some more changes and tried again. Looking back at these numbers, I'm a little skeptical because they seem a little too good in comparison to my other runs...<br/>
![run 1](https://aeraposo.github.io/Data-310-Public-Raposo/p3_1.png)

  - **Run 2:** Next, I increased my batch size to 1,000 training images and 100 test images. I kept epochs, steps_per_epoch, and batch_size the same and had results in under an hour. This time, loss increased to 877.9531 and MAE to 25.5498. Chalking the decrease in performance up to small batch sizes, I ran the model a third and final time.<br/>
![run 2](https://aeraposo.github.io/Data-310-Public-Raposo/p3_2.png)

  - **Run 3:** For this run, I reused the 1,000 image training set and 100 image testing set and set epochs=10, steps_per_epoch = 10, and batch_size = 100. I kept these numbers relatively low out of fear for miscalculations resulting in insifficient data. After 8 hours, the following was returned loss: 878.0463, MAE: 25.5515. Saddly, the performance decreased yet again.<br/>
![run 3](https://aeraposo.github.io/Data-310-Public-Raposo/p3_3.png)

  - **Run 4:** Lastly, loss: 106.3372 - MAE: 7.5652
  
  
- **Remarks about the graphs:** Its interesting how they retained the same general trend

**Applications:**<br/>
Although my model was highly innacurate, similar models could be very useful in the following ways:
- Community growth planning: By imaging large areas and estimating population, community/city growth planners could gauge the number of people imacted my construction, new roads/buildings, and determine where these expansions could be possible. A modified version of this model might also be able to predict vehicular traffic at certain times/places.<br/>
- Population growth: Similarly, this model could be used to monitor population growth over time. This technology could also have applications in surviellence and security of high-traffic areas.<br/>
- Farming and nature: On large farms, this model could be modified to track livestock. This model could also be adapted to track specific species in the wild- perhaps a way to monitor endangered species without infringing on their habitat. 


**Ways to improve:**<br/>
My PyCharm will not show matplotlib plots, even with simple examples so I produced the above in graphs in Google Colab. This definitely limited what plots I was able to make. If I was able, I would have produced plots of validation MSE and MAE and a plot showing the convolutions for an image (I didn't reload the notebook becuase I would have had to rerun the fit, which took 8 hours last time with just 1 convolution).<br/>
In the future, I would like to add more convolution and pooling layers to see how accuracy would change. This would make a cool graph too (how scores changed over convolutions).
